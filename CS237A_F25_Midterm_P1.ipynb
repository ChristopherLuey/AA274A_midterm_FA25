{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQtyxYSvUgJB"
   },
   "source": [
    "In this problem we will be implementing components of iLQR and Gain Scheduled LQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLqKdrMTSZOy",
    "outputId": "e665506a-dafa-4ec6-e4fc-91b92e63f26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded real_model_blind.npz\n"
     ]
    }
   ],
   "source": [
    "# Package Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from __future__ import annotations\n",
    "from typing import Callable, Optional\n",
    "import urllib.request\n",
    "\n",
    "base_url = \"https://github.com/PrinciplesofRobotAutonomy/AA274A_midterm_FA25/raw/main/data/\"\n",
    "files = [\"real_model_blind.npz\"]\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    urllib.request.urlretrieve(url, file)\n",
    "    print(f\"Downloaded {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3xR17MsTNdU"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "m = 1.0\n",
    "g = 9.81\n",
    "ell = 0.25\n",
    "Izz = 0.025\n",
    "dt_default = 0.02\n",
    "T_hov = m * g / 2.0\n",
    "\n",
    "# Cost weights\n",
    "q_p = 10.0\n",
    "q_v = 2.0\n",
    "q_phi = 5.0\n",
    "q_omega = 1.0\n",
    "\n",
    "##### CHANGE FOR PART D ######\n",
    "r_T = 1e-3\n",
    "\n",
    "goal = np.array([1.5, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
    "hover_u = np.array([T_hov, T_hov])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wv0hajlTxcDF"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGGvnOUwxSOE"
   },
   "outputs": [],
   "source": [
    "class RealWorld:\n",
    "    \"\"\"\n",
    "    RealWorld(dt, path=\"data/real_model_blind.npz\", seed=274)\n",
    "\n",
    "    Produces a function f_real_step(x, u, t) that:\n",
    "      1) adds tiny command jitter to u (optional)\n",
    "      2) applies hidden per-rotor thrust scaling\n",
    "      3) advances state with the *nominal* f_discrete(x, u_scaled, dt)\n",
    "      4) injects hidden accel biases into (vx, vy) via a post-step delta\n",
    "\n",
    "    The binary blob contains:\n",
    "      - scale_T: (2,) multiplicative thrust scales [alpha1, alpha2]\n",
    "      - drift_mg: (2,) (kept for future; not used directly with pure discrete stepping)\n",
    "      - geom: (2,) (kept for future; not used directly with pure discrete stepping)\n",
    "      - bias_axay: (T, 2) per-step acceleration biases in (ax, ay)\n",
    "      - noise_u: (T, 2) optional tiny control noise per step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dt: float, path: str = \"data/real_model_blind.npz\", seed: int = 274):\n",
    "        self.dt = float(dt)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        blob = np.load(path)\n",
    "\n",
    "        # Required keys (opaque to students)\n",
    "        self.scale_T   = np.asarray(blob[\"scale_T\"], dtype=float)        # (2,)\n",
    "        self.bias_axay = np.asarray(blob[\"bias_axay\"], dtype=float)      # (T, 2)\n",
    "\n",
    "        # Optional/legacy keys (loaded but not required for the discrete wrapper)\n",
    "        self.noise_u   = np.asarray(blob[\"noise_u\"], dtype=float) if \"noise_u\" in blob else None\n",
    "        self.drift_mg  = np.asarray(blob.get(\"drift_mg\", [1.0, 1.0]), dtype=float)\n",
    "        self.geom      = np.asarray(blob.get(\"geom\", [0.25, 0.025]), dtype=float)\n",
    "\n",
    "        self._T = self.bias_axay.shape[0]\n",
    "\n",
    "    def make_step(self, f_discrete_nominal: Callable[[np.ndarray, np.ndarray, float], np.ndarray]\n",
    "                 ) -> Callable[[np.ndarray, np.ndarray, int], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Returns: f_real_step(x, u_cmd, t) -> x_{t+1} under hidden 'real' effects,\n",
    "                 using ONLY the nominal f_discrete_nominal call internally.\n",
    "        \"\"\"\n",
    "\n",
    "        alpha1, alpha2 = float(self.scale_T[0]), float(self.scale_T[1])\n",
    "        dt = self.dt\n",
    "\n",
    "        def f_real_step(x: np.ndarray, u_cmd: np.ndarray, t: int) -> np.ndarray:\n",
    "            # 1) tiny command jitter (if provided)\n",
    "            u = u_cmd.copy()\n",
    "            if self.noise_u is not None and 0 <= t < self.noise_u.shape[0]:\n",
    "                u = u + self.noise_u[t]\n",
    "\n",
    "            # 2) hidden per-rotor thrust scale (actuator miscalibration)\n",
    "            #    works for any 2D input of the thrust pair [T1, T2]\n",
    "            u_scaled = u.copy()\n",
    "            u_scaled[0] = alpha1 * u_scaled[0]\n",
    "            u_scaled[1] = alpha2 * u_scaled[1]\n",
    "\n",
    "            # 3) advance one step via nominal discrete dynamics\n",
    "            x_next = f_discrete_nominal(x, u_scaled, dt)\n",
    "\n",
    "            # 4) inject hidden acceleration biases by nudging velocities\n",
    "            #    v_{x,y}(t+1) += dt * a_bias(t)\n",
    "            if t < self._T:\n",
    "                ax_bias, ay_bias = self.bias_axay[t]\n",
    "            else:\n",
    "                ax_bias, ay_bias = self.bias_axay[-1]  # hold last value\n",
    "            x_next = x_next.copy()\n",
    "            x_next[1] += dt * float(ax_bias)  # vx\n",
    "            x_next[3] += dt * float(ay_bias)  # vy\n",
    "\n",
    "            return x_next\n",
    "\n",
    "        return f_real_step\n",
    "\n",
    "\n",
    "def plot_planar_trajectory(X_ilqr, X_gslqr=None, goal=(1.5, 1.0)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(X_ilqr[:,0], X_ilqr[:,2], '-r', lw=2, label=\"iLQR trajectory\")\n",
    "    if X_gslqr is not None:\n",
    "        plt.plot(X_gslqr[:,0], X_gslqr[:,2], '-b', lw=2, label=\"GS-LQR trajectory\")\n",
    "    plt.scatter([0, goal[0]], [0, goal[1]], c=['k','g'], marker='x', s=80, label=\"Start / Goal\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlabel(\"$p_x$ (m)\")\n",
    "    plt.ylabel(\"$p_y$ (m)\")\n",
    "    plt.title(\"Planar Trajectories\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rollout_cost(X, U):\n",
    "    J = 0.0\n",
    "    Q  = np.diag([10.0, 2.0, 10.0, 2.0, 5.0, 1.0])\n",
    "    R  = np.diag([1e-3, 1e-3])\n",
    "    Qf = Q  # keeps the comparison neutral and consistent with your iLQR demo\n",
    "    x_star = np.array([1.5, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
    "    u_star = np.array([T_hov, T_hov])\n",
    "\n",
    "    for t in range(U.shape[0]):\n",
    "        dx = X[t] - x_star\n",
    "        du = U[t] - u_star\n",
    "        J += dx @ Q @ dx + du @ R @ du\n",
    "    dxT = X[-1] - x_star\n",
    "    J += dxT @ Qf @ dxT\n",
    "    return float(J)\n",
    "\n",
    "def plot_time_series(X, U, dt, title=\"\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    tX = np.arange(X.shape[0]) * dt     # length T+1\n",
    "    tU = np.arange(U.shape[0]) * dt     # length T\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(8, 8), sharex=False)\n",
    "    axs[0].plot(tX, X[:, 0], label=\"p_x\")\n",
    "    axs[0].plot(tX, X[:, 2], label=\"p_y\")\n",
    "    axs[0].set_ylabel(\"position (m)\"); axs[0].legend()\n",
    "\n",
    "    axs[1].plot(tX, X[:, 4] * 180 / np.pi, label=\"phi (deg)\")\n",
    "    axs[1].set_ylabel(\"attitude (deg)\"); axs[1].legend()\n",
    "\n",
    "    axs[2].plot(tU, U[:, 0], label=\"T1\")\n",
    "    axs[2].plot(tU, U[:, 1], label=\"T2\")\n",
    "    axs[2].set_ylabel(\"thrust (N)\"); axs[2].set_xlabel(\"time (s)\"); axs[2].legend()\n",
    "\n",
    "    fig.suptitle(title); plt.tight_layout()\n",
    "\n",
    "def dlqr_infinite_horizon(A, B, Q, R):\n",
    "    \"\"\"\n",
    "    Solve the infinite-horizon discrete-time LQR problem.\n",
    "        minimize sum (x'Qx + u'Ru)\n",
    "        subject to x_{t+1} = A x_t + B u_t\n",
    "    Returns:\n",
    "        K: feedback gain (u = -Kx)\n",
    "        S: solution to discrete algebraic Riccati equation\n",
    "    \"\"\"\n",
    "    S = solve_discrete_are(A, B, Q, R)\n",
    "    K = np.linalg.inv(B.T @ S @ B + R) @ (B.T @ S @ A)\n",
    "    return K, S\n",
    "\n",
    "def minjerk_poly(x0, xf, tf, tvec):\n",
    "    \"\"\"Return position, velocity, acceleration along a 1D minimum-jerk trajectory.\"\"\"\n",
    "    # normalized time\n",
    "    s = np.clip(tvec / tf, 0, 1)\n",
    "    s2 = s*s; s3 = s2*s; s4 = s3*s; s5 = s4*s\n",
    "    # poly\n",
    "    p = x0 + (xf - x0) * (10*s3 - 15*s4 + 6*s5)\n",
    "    v = (xf - x0) * (30*s2 - 60*s3 + 30*s4) / tf\n",
    "    a = (xf - x0) * (60*s - 180*s2 + 120*s3) / (tf**2)\n",
    "    return p, v, a\n",
    "\n",
    "def build_reference(T=150):\n",
    "    tf = T * dt_default\n",
    "    t = np.linspace(0, tf, T+1)\n",
    "    px, vx, ax = minjerk_poly(0, 1.5, tf, t)\n",
    "    py, vy, ay = minjerk_poly(0, 1.0, tf, t)\n",
    "\n",
    "    Tsum = np.sqrt((ay + 9.81)**2 + (ax)**2)\n",
    "    phi_ref = np.arctan2(-ax, ay + 9.81)\n",
    "\n",
    "    xref = np.stack([px, vx, py, vy, phi_ref, np.zeros_like(phi_ref)], axis=1)\n",
    "    uref = np.stack([Tsum/2, Tsum/2], axis=1)\n",
    "    return xref, uref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnf91Mv1yQk2"
   },
   "source": [
    "# Midterm Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5MASAL5VJq3"
   },
   "source": [
    "Part a.) Implement the dynamics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jvtxMOTTNik"
   },
   "outputs": [],
   "source": [
    "def f_continuous(x, u):\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    # Write the continuous dynamics for the planar drone\n",
    "    T1, T2 = u\n",
    "    px, vx, py, vy, phi, omega = x\n",
    "    thrust_sum = T1 + T2\n",
    "    dx = np.zeros_like(x, dtype=float)\n",
    "    dx[0] = vx\n",
    "    dx[1] = -(thrust_sum / m) * np.sin(phi)\n",
    "    dx[2] = vy\n",
    "    dx[3] = (thrust_sum / m) * np.cos(phi) - g\n",
    "    dx[4] = omega\n",
    "    dx[5] = ((T2 - T1) * ell) / Izz\n",
    "    ######################################################################\n",
    "    return dx\n",
    "\n",
    "def f_discrete(x, u, dt=dt_default):\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    # Write the discrete dynamics for the planar drone\n",
    "    dx = x + dt * f_continuous(x, u)\n",
    "    ######################################################################\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXrLKN1yh_UR"
   },
   "source": [
    "Part b.) Implement the per-timestep running cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm0yOv8NTNm2"
   },
   "outputs": [],
   "source": [
    "def running_cost(x, u):\n",
    "  px, vx, py, vy, phi, omega = x\n",
    "  T1, T2 = u\n",
    "  ex = px - goal[0]\n",
    "  ey = py - goal[2]\n",
    "  cost = (\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    # Write the per timestep running cost here\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "  )\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wBDepdqiXG2"
   },
   "source": [
    "Part c.) Implement the continuous and discrete time Jacobian functions and use them to implement the linearize about function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfzAfCfCio97"
   },
   "outputs": [],
   "source": [
    "def continuous_jacobians(x, u):\n",
    "    px, vx, py, vy, phi, omega = x\n",
    "    T1, T2 = u\n",
    "    A_c = np.zeros((6, 6))\n",
    "    B_c = np.zeros((6, 2))\n",
    "\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    return A_c, B_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdtLuwvioJF0"
   },
   "outputs": [],
   "source": [
    "def discrete_jacobians(A_c, B_c, dt):\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    return A_t, B_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ81r0BFoJIj"
   },
   "outputs": [],
   "source": [
    "def linearize_about(x_ref, u_ref, dt=dt_default):\n",
    "    \"\"\"\n",
    "    Affine first-order discrete-time expansion about (x_ref, u_ref):\n",
    "        x_ref{t+1} â‰ˆ f_d(x_ref,u_ref) + A_t (x_ref) + B_t (u_ref)\n",
    "    \"\"\"\n",
    "    A_c, B_c = continuous_jacobians(x_ref, u_ref)\n",
    "    ######################################################################\n",
    "    ######################### YOUR CODE HERE #############################\n",
    "    # Use the discrete_jacobians(A_c, A_b) for A_t and B_t\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    return A_t, B_t, x_next_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRtvO7I9x0Z_"
   },
   "source": [
    "# iLQR Results (Run and Discuss Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozJ0mCWox5NN"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "def ilqr(x0, U0, T=150, max_iter=50, tol=1e-4, u_min=0.0, u_max=2*2*9.81/2):\n",
    "    \"\"\"\n",
    "    Minimal iLQR, fixed horizon T.\n",
    "    Cost is sum of running_cost; no explicit terminal cost here.\n",
    "    \"\"\"\n",
    "    n = x0.size\n",
    "    m = U0.shape[1]\n",
    "    U = U0.copy()\n",
    "    X = np.zeros((T+1, n))\n",
    "    X[0] = x0\n",
    "\n",
    "    def rollout(X, U):\n",
    "        for t in range(T):\n",
    "            u = np.clip(U[t], u_min, u_max)\n",
    "            X[t+1] = f_discrete(X[t], u, dt_default)\n",
    "        return X\n",
    "\n",
    "    X = rollout(X, U)\n",
    "\n",
    "    # quadratic cost derivatives (exact for quadratic running_cost):\n",
    "    Qx = lambda x: np.array([\n",
    "        2*10*(x[0]-goal[0]),\n",
    "        2*2*x[1],\n",
    "        2*10*(x[2]-goal[2]),\n",
    "        2*2*x[3],\n",
    "        2*5*x[4],\n",
    "        2*1*x[5]\n",
    "    ])\n",
    "    Qu = lambda u: np.array([\n",
    "        2*1e-3*(u[0]-T_hov),\n",
    "        2*1e-3*(u[1]-T_hov)\n",
    "    ])\n",
    "    Qxx = np.diag([2*10, 2*2, 2*10, 2*2, 2*5, 2*1])\n",
    "    Quu = np.diag([2*1e-3, 2*1e-3])\n",
    "    Qux = np.zeros((m, n))\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        # backward pass\n",
    "        Vx = Qx(X[-1])\n",
    "        Vxx = Qxx.copy()\n",
    "        K = np.zeros((T, m, n))\n",
    "        k = np.zeros((T, m))\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            At, Bt, _ = linearize_about(X[t], U[t])\n",
    "            # Q-function quadratic approx\n",
    "            Qx_t = Qx(X[t]) + At.T @ Vx\n",
    "            Qu_t = Qu(U[t]) + Bt.T @ Vx\n",
    "            Qxx_t = Qxx + At.T @ Vxx @ At\n",
    "            Quu_t = Quu + Bt.T @ Vxx @ Bt\n",
    "            Qux_t = Qux + Bt.T @ Vxx @ At\n",
    "\n",
    "            # regularization (tiny) to avoid singular Quu\n",
    "            Quu_reg = Quu_t + 1e-9*np.eye(m)\n",
    "            K[t] = -np.linalg.solve(Quu_reg, Qux_t)\n",
    "            k[t] = -np.linalg.solve(Quu_reg, Qu_t)\n",
    "\n",
    "            Vx = Qx_t + K[t].T @ Quu_t @ k[t] + K[t].T @ Qu_t + Qux_t.T @ k[t]\n",
    "            Vxx = Qxx_t + K[t].T @ Quu_t @ K[t] + K[t].T @ Qux_t + Qux_t.T @ K[t]\n",
    "            Vxx = 0.5 * (Vxx + Vxx.T)  # symmetrize\n",
    "\n",
    "        # forward rollout\n",
    "        X_new = np.zeros_like(X)\n",
    "        U_new = np.zeros_like(U)\n",
    "        X_new[0] = X[0]\n",
    "        J = 0.0\n",
    "        for t in range(T):\n",
    "            du = k[t] + K[t] @ (X_new[t] - X[t])\n",
    "            U_new[t] = np.clip(U[t] + du, u_min, u_max)\n",
    "            X_new[t+1] = f_discrete(X_new[t], U_new[t])\n",
    "            J += running_cost(X_new[t], U_new[t])\n",
    "        J += running_cost(X_new[-1], hover_u)  # mild terminal term reuse\n",
    "\n",
    "        costs.append(J)\n",
    "\n",
    "        # convergence check\n",
    "        if it > 0:\n",
    "            rel = abs(costs[-2] - costs[-1]) / max(1.0, abs(costs[-2]))\n",
    "            if rel < tol:\n",
    "                X, U = X_new, U_new\n",
    "                break\n",
    "\n",
    "        X, U = X_new, U_new\n",
    "\n",
    "    return X, U, np.array(costs)\n",
    "\n",
    "T = 150\n",
    "x0 = np.zeros(6)\n",
    "U0 = np.tile(hover_u, (T, 1))\n",
    "X_ilqr, U, costs = ilqr(x0, U0, T=T)\n",
    "\n",
    "\n",
    "rw = RealWorld(dt_default, path=\"/content/real_model_blind.npz\")\n",
    "f_real_step = rw.make_step(f_discrete)\n",
    "\n",
    "# Replay iLQR controls open-loop on real dynamics\n",
    "X_ilqr_real = np.zeros_like(X_ilqr)\n",
    "X_ilqr_real[0] = X_ilqr[0]\n",
    "for t in range(U.shape[0]):\n",
    "    X_ilqr_real[t+1] = f_real_step(X_ilqr_real[t], U[t], t)\n",
    "\n",
    "J_total = rollout_cost(X_ilqr_real, U)\n",
    "print(\"iLQR closed-loop rollout cost estimate:\", J_total)\n",
    "\n",
    "# plots\n",
    "t = np.arange(X_ilqr_real.shape[0]) * dt_default\n",
    "plot_time_series(X_ilqr_real, U, dt_default, title=\"iLQR Trajectory\")\n",
    "plt.figure(); plt.plot(costs); plt.title(\"iLQR cost\"); plt.xlabel(\"iteration\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzn6XnIYyZoH"
   },
   "source": [
    "# GS-LQR Results (Run and Discuss Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mxmUHDtycGB"
   },
   "outputs": [],
   "source": [
    "# Cost weights\n",
    "Q = np.diag([10, 2, 10, 2, 5, 1])\n",
    "R = np.diag([1e-3, 1e-3])\n",
    "T = 150\n",
    "xref, uref = build_reference(T)\n",
    "\n",
    "X_gslqr = np.zeros_like(xref)\n",
    "U = np.zeros_like(uref)\n",
    "X_gslqr[0] = np.zeros(6)\n",
    "\n",
    "# Outside the loop (once):\n",
    "rw = RealWorld(dt_default, path=\"/content/real_model_blind.npz\")\n",
    "f_real_step = rw.make_step(f_discrete)\n",
    "\n",
    "for t in range(T):\n",
    "    A_t, B_t, _ = linearize_about(xref[t], uref[t])\n",
    "    # Compute infinite-horizon LQR gain\n",
    "    K_t, _ = dlqr_infinite_horizon(A_t, B_t, Q, R)\n",
    "\n",
    "    # Apply local LQR feedback law\n",
    "    u_fb = -K_t @ (X_gslqr[t] - xref[t])\n",
    "    U[t] = np.clip(uref[t] + u_fb, 0.0, 2*T_hov)\n",
    "    X_gslqr[t+1] = f_real_step(X_gslqr[t], U[t], t)\n",
    "\n",
    "J_total = rollout_cost(X_gslqr, U)\n",
    "print(\"GS-LQR closed-loop rollout cost estimate:\", J_total)\n",
    "\n",
    "tvec = np.arange(T+1) * dt_default\n",
    "plot_time_series(X_gslqr, U, dt_default, title=\"Gain-Scheduled LQR Tracking\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fu9LKoWIYmhQ"
   },
   "outputs": [],
   "source": [
    "# Comparison of the closed loop trajectories\n",
    "plot_planar_trajectory(X_ilqr_real, X_gslqr, goal=(1.5,1.0))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
